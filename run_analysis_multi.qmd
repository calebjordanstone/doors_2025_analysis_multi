---
title: "Honours Analysis 2025 - Multi"
format: html
embed-resources: true
editor: visual
execute-dir: project
---

```{r}
#| output: false

# load libraries
library(afex)
library(emmeans)
library(data.table)
library(ggpubr)
library(tidyverse)
library(stringr)

# set emmeans option to multivariate
afex_options(emmeans_model = "multivariate") # use multivariate for RM designs
```

# Multi-tasking experiment

```{r}
# assign experiment label
exp <- 'multi'

# load data
avg_multi <- fread('data/exp-multi_avg.csv')
avg_multi_mts <- fread('data/exp-multi_mts_avg.csv')

# change factor level names
avg_multi[, switch := ifelse(switch==0, 'non-switch', 'switch')]
avg_multi[, train_type := ifelse(train_type==1,'stable', 'variable')]
avg_multi[, ses := ifelse(ses==2, 'training', 'testing')]

avg_multi_mts <- avg_multi_mts[unique(avg_multi[, .(sub, train_type)]), on='sub']
avg_multi_mts[, cond := ifelse(cond=='nc', 'neither', 'other')]
avg_multi_mts[, stage := ifelse(stage=='3', 'testing', 'initial')]
avg_multi_mts[, train_type := ifelse(train_type==1, 'stable', 'variable')]
setnames(avg_multi_mts, 'stage', 'ses') 

```

## Testing session

```{r}
# assign session label
ses <- 'test'

```

#### Defining contrasts of interest

Here I define a set of contrasts according to the following procedure/principles:

1.  We have pre-defined hypotheses about specific differences we are interested in
2.  We have collected data using a factorial ANOVA design
3.  Because of #1, we can define a priori contrast vectors we are interested in testing
4.  Because of #2, we can determine that contrast vectors that are orthogonal to each other constitute independent tests. Those that are not orthogonal to each other constitute dependent tests. Thus we group our contrasts into sets. Within a set, contrasts should be non-orthogonal. Across sets, they should be non-orthogonal. This creates our families of tests.
5.  Each family should be controlled at $\alpha$ = .05. If there is only one contrast in the family, then the effect is tested at p=.05. If there is more than one contrast in the family, then we apply a Bonferonni correction to the tests (as the family is a priori defined).

```{r}

# adapting the code above to test the key hypotheses of the study. Under each section of comments, I have built up to the contrast that tests the hypothesis of interest. Then I test for orthogonality, to guide how to control the error rate during hypothesis testing.

ngrps <- 2
n_multi <- 3 # levels of multitasking
n_trial_type <- 2 # levels of search trial type (first vs subsequent)

##### apriori (to apply bonferroni correction on orthogonal sets of contrasts)
# first, we hypothesise that performance should be different on the neither/other trials compared to the none trials, for the first of the search trials
multi_vs_sing <- rep(c(1/2, -1, 1/2, 0, 0, 0), times=ngrps)

# next, we hypothesise that the performance difference on other trials should be worse than on neither trials, for the first of the search trials.
neither_vs_other <- rep(c(1, 0, -1, 0, 0, 0), times=ngrps)

# adding other combinations of multi_cond
neither_vs_none <- rep(c(1, -1, 0, 0, 0, 0), time=ngrps)
none_vs_other <- rep(c(0, 1, -1, 0, 0, 0), time=ngrps)

# next we predict that this difference on other vs neither trials should be worse for the variable group, compared to the stable group, as the latter group should suffer less cross-task interference 
group <- rep(c(-1, 1), each=n_multi*n_trial_type)
group_by_multi_neither_vs_other <- multi_neither_vs_other * group

# next, we want to know, is the difference between neither/other trials vs none trials, different for first, compared to subsequent search trials? i.e. we predict that the impact of multitasking should reduce from the first to subsequent search trials
first_vs_subs <- rep(c(1, 1, 1, -1, -1, -1), times=ngrps)
multi_vs_sing_both <- rep(c(1/2, -1, 1/2), times=ngrps*n_trial_type)
first_vs_subs_by_multi_vs_sing <- first_vs_subs * multi_vs_sing_both 

# next, we want to know, is the difference between neither than other different for first to subsequent search trials. We predict that any difference should reduce
multi_neither_vs_other_full <- c(1, 0, -1, 1, 0, -1)
first_vs_subs_by_neither_vs_other <- first_vs_subs * multi_neither_vs_other_full

# last, we predict that both of the above effects should be smaller for the variable group compared to the stable group
group_by_first_vs_subs_by_multi_vs_sing <- group * first_vs_subs_by_multi_vs_sing
group_by_first_vs_subs_by_neither_vs_other <- group * first_vs_subs_by_neither_vs_other

# now we have our key contrasts, we can check if they are orthogonal.
# first, I turn them into a matrix
n_contrasts <- 7
all_contrasts <- matrix(c(multi_vs_sing_first, # 1
                          multi_neither_vs_other, # 2
                          group_by_multi_neither_vs_other, # 3 
                          first_vs_subs_by_multi_vs_sing, # 4
                          first_vs_subs_by_neither_vs_other, # 5
                          group_by_first_vs_subs_by_multi_vs_sing, # 6
                          group_by_first_vs_subs_by_neither_vs_other), byrow=FALSE, ncol=n_contrasts)
# compute the gram matrix (i.e. the dot product between all pairs of vectors)
G <- t(all_contrasts) %*% all_contrasts # note that if the vectors are all orthogonal, then the off diagonal enties will be zero, any non-orthognal contrasts will have an off-diagonal element that is different to zero
G # look at G
# I can see that contrasts 1 & 4 are correlated (non-orthogonal) so bonferroni adjustment needs to be applied to these two together, when testing the contrast. 
# 2 & 5 are also non-orthogonal
# 3 & 7 are also non-orthogonal
# The rest are independent to the others so can each be tested at p<.05. So lets define the families now
# I am making the families manually. One day, dream coder Kelly or Caleb will automate this based on the indexes of the off-diagonal elements > 0 :)
fam_multi_vs_sing_first <- list(multi_vs_sing_first = multi_vs_sing_first, # 1
                               first_vs_subs_by_multi_vs_sing = first_vs_subs_by_multi_vs_sing) # 4
                                   
fam_multi_neither_vs_other <- list(multi_neither_vs_other = multi_neither_vs_other, #2
                                   first_vs_subs_by_neither_vs_other = first_vs_subs_by_neither_vs_other) #5

fam_group_w_one_within <- list(group_by_multi_neither_vs_other = group_by_multi_neither_vs_other, # 3
                                           group_by_first_vs_subs_by_neither_vs_other = group_by_first_vs_subs_by_neither_vs_other) # 7

fam_group_by_first_vs_subs_by_multi_vs_sing <- list(group_by_first_vs_subs_by_multi_vs_sing=group_by_first_vs_subs_by_multi_vs_sing) # 6

# note that any tests beyond this point will be post-hoc simple effect comparisons, will be non-orthognal. After each of the above contrast tests, we should determine any post-hoc tests we want to do, which will determine how we control for them.


```

### Accuracy

Here we apply the above defined contrasts to the accuracy data

```{r}

# assign variable label
var <- 'accuracy'

# specify model
mdl <- aov_ez(id = 'sub',
              within = c('multi_cond', 'multi_trial'), 
              between = 'train_type',
              dv = 'accuracy_mean',
              data = avg_multi[ses=='testing'])

# get estimated marginal means from the model
emm_int <- emmeans(mdl, c('multi_cond', 'multi_trial', 'train_type'))

# inspect means
emm_int

```

Now compute contrasts for each family

First, the family that cares about whether accuracy was lower on multitask compared to single task trials, for the first of the search trials, and whether this multitasking cost reduced when moving from the first to subsequent search trials.

```{r}

## compute contrasts for each family
cntrsts_fam_multi_vs_sing_first <- contrast(emm_int, fam_multi_vs_sing_first, adjust='bonferroni')

cntrsts_fam_multi_vs_sing_first
```

So now we know that accuracy was significantly lower on multitask compared to single task trials for the first of the search trials, and that this difference reduced from first to subsequent search trials. Neat!

Now for the family that cares about whether neither and other trials are different from each other...

```{r}

cntrsts_fam_multi_neither_vs_other <- contrast(emm_int, fam_multi_neither_vs_other, adjust='bonferroni')
cntrsts_fam_multi_neither_vs_other
```

Resounding no on those.

Now we look at the family which cares about the interaction of group with one within subjects factor - either the multi vs single, or neither vs other -

```{r}

cntrst_fam_group_w_one_within <- contrast(emm_int, fam_group_w_one_within, adjust='bonferroni')
cntrst_fam_group_w_one_within

```

Also a resounding no.

And last, we look at our last interaction of interest - the group x multi_vs_sing x first_vs_subs

```{r}

cntrsts_fam_group_by_first_vs_subs_by_multi_vs_sing <- contrast(emm_int, fam_group_by_first_vs_subs_by_multi_vs_sing, adjust='bonferroni')
cntrsts_fam_group_by_first_vs_subs_by_multi_vs_sing
```

Also a resounding no :)

Now I write a function that automatically applies these contrast families to a table of emms, given you have the list of families and the dv -

```{r}

# a function to rule them all
list_of_contrast_lists <- list(fam_multi_vs_sing_first, 
                               fam_multi_neither_vs_other,
                               fam_group_w_one_within,
                               fam_group_by_first_vs_subs_by_multi_vs_sing)

get_all_contrasts <- function(this_dv, list_of_contrast_lists){
  
  # specify model
  mdl <- aov_ez(id = 'sub',
                within = c('multi_cond', 'multi_trial'), 
                between = 'train_type',
                dv = this_dv,
                data = avg_multi[ses=='testing'])
  
  # generate means
  emm_int <- emmeans(mdl, c('multi_cond', 'multi_trial', 'train_type'))
  
    # plot 
  p <- afex_plot(mdl, 
          x = 'multi_cond', 
          trace = 'train_type', 
          panel = 'multi_trial',
          error = "within", 
          data_plot = F) + 
  theme_pubclean()
  
  # compute contrasts
  c <- do.call(rbind, lapply(list_of_contrast_lists, function(x) summary(contrast(emm_int, x, adjust='bonferroni'))))
  
  # return output
  return(list(means=emm_int, plot=p, contrasts=c)) #made this return some additional information for interpreting the results
}
```

### Accuracy

```{r}
# assign variable label
var <- 'accuracy'

# compute contrasts
res <- get_all_contrasts('accuracy_mean', list_of_contrast_lists)

# show results
res$means
res$plot
res$contrasts

# save result
dt <- data.table(res$contrasts)
dt[, names(.SD) := lapply(.SD, round, 2), .SDcols=c('estimate', 'SE', 'df', 't.ratio')
][, names(.SD) := lapply(.SD, round, 3), .SDcols=c('p.value')]
fln <- str_glue("res/contrasts_exp-{exp}_ses-{ses}_{var}.csv")
write_csv(dt, fln)
```

### Setting errors

```{r}
var <- 'setting_errors'

# compute contrasts
res <- get_all_contrasts('setting_errors_mean', list_of_contrast_lists)

# show results
res$means
res$plot
res$contrasts

# save result
dt <- data.table(res$contrasts)
dt[, names(.SD) := lapply(.SD, round, 2), .SDcols=c('estimate', 'SE', 'df', 't.ratio')
][, names(.SD) := lapply(.SD, round, 3), .SDcols=c('p.value')]
fln <- str_glue("res/contrasts_exp-{exp}_ses-{ses}_{var}.csv")
write_csv(dt, fln)
```

### General errors

```{r}
var <- 'general_errors'

# compute contrasts
res <- get_all_contrasts('general_errors_mean', list_of_contrast_lists)

# show results
res$means
res$plot
res$contrasts

# save result
dt <- data.table(res$contrasts)
dt[, names(.SD) := lapply(.SD, round, 2), .SDcols=c('estimate', 'SE', 'df', 't.ratio')
][, names(.SD) := lapply(.SD, round, 3), .SDcols=c('p.value')]
fln <- str_glue("res/contrasts_exp-{exp}_ses-{ses}_{var}.csv")
write_csv(dt, fln)
```

### RT first correct

```{r}
var <- 'rt_first_cor'

# compute contrasts
res <- get_all_contrasts('rt_first_correct_mean', list_of_contrast_lists)

# show results
res$means
res$plot
res$contrasts

# save result
dt <- data.table(res$contrasts)
dt[, names(.SD) := lapply(.SD, round, 2), .SDcols=c('estimate', 'SE', 'df', 't.ratio')
][, names(.SD) := lapply(.SD, round, 3), .SDcols=c('p.value')]
fln <- str_glue("res/contrasts_exp-{exp}_ses-{ses}_{var}.csv")
write_csv(dt, fln)
```

### RT subs correct

```{r}
var <- 'rt_subs_cor'

# compute contrasts
res <- get_all_contrasts('rt_subs_correct_mean', list_of_contrast_lists)

# show results
res$means
res$plot
res$contrasts

# save result
dt <- data.table(res$contrasts)
dt[, names(.SD) := lapply(.SD, round, 2), .SDcols=c('estimate', 'SE', 'df', 't.ratio')
][, names(.SD) := lapply(.SD, round, 3), .SDcols=c('p.value')]
fln <- str_glue("res/contrasts_exp-{exp}_ses-{ses}_{var}.csv")
write_csv(dt, fln)
```

## Training session

```{r}
ses <- 'train'

## define contrasts for analysis
# effect of train_type
stable_vs_variable <- list(stable_vs_variable = c(1, -1))
```

### Setting errors

```{r}
var <- 'setting_errors'


```

### General errors

```{r}
var <- 'general_errors'


```

# Working memory task

```{r}
task <- 'wmt'

```

## Accuracy

```{r}
# assign variable label
var <- 'accuracy'

```

## Reaction time

```{r}
# assign variable label
var <- 'rt'

```
